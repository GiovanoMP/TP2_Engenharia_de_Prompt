{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo de Tokens em Texto Longo com API Gemini\n",
    "\n",
    "Implemente um notebook que use a API Gemini para calcular a quantidade de tokens necessários para processar um texto de 5.000 palavras. Baseie-se no modelo de tokenização utilizado por Gemini e explique como a quantidade de tokens influencia o custo e o desempenho da interação com LLMs em textos longos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carregar variáveis de ambiente\n",
    "load_dotenv()\n",
    "\n",
    "# Configurar a API do Gemini\n",
    "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gerar um texto de exemplo\n",
    "def gerar_texto_exemplo(num_palavras=5000):\n",
    "    \"\"\"\n",
    "    Gera um texto de exemplo com o número especificado de palavras\n",
    "    \"\"\"\n",
    "    # Texto base que será repetido\n",
    "    texto_base = \"\"\"\n",
    "    A inteligência artificial tem revolucionado diversos setores da sociedade moderna. \n",
    "    Desde aplicações em saúde até sistemas de transporte inteligente, a IA está presente \n",
    "    em praticamente todas as áreas do conhecimento humano. O processamento de linguagem \n",
    "    natural, em particular, tem apresentado avanços significativos nos últimos anos, \n",
    "    permitindo interações mais naturais entre humanos e máquinas.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calcular quantas vezes precisamos repetir o texto\n",
    "    palavras_por_texto = len(texto_base.split())\n",
    "    repeticoes = (num_palavras // palavras_por_texto) + 1\n",
    "    \n",
    "    # Gerar texto final\n",
    "    texto_completo = \" \".join([texto_base] * repeticoes)\n",
    "    \n",
    "    # Garantir exatamente 5000 palavras\n",
    "    palavras = texto_completo.split()[:num_palavras]\n",
    "    return \" \".join(palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_tokens(texto):\n",
    "    \"\"\"\n",
    "    Analisa a quantidade de tokens em um texto usando o Gemini\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Analise o seguinte texto e forneça:\n",
    "    1. Número aproximado de tokens\n",
    "    2. Razão tokens/palavras\n",
    "    3. Custo estimado (considerando $0.001 por 1K tokens)\n",
    "    4. Recomendações para otimização\n",
    "\n",
    "    Texto para análise:\n",
    "    {texto[:1000]}... [texto continua por mais {len(texto)-1000} caracteres]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Erro na análise: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando texto de 5000 palavras...\n",
      "\n",
      "Tamanho do texto gerado:\n",
      "- Caracteres: 37265\n",
      "- Palavras: 5000\n",
      "\n",
      "Analisando tokens com Gemini...\n",
      "\n",
      "Resultado da análise:\n",
      "**1. Número aproximado de tokens:**\n",
      "* 24.500\n",
      "\n",
      "**2. Razão tokens/palavras:**\n",
      "* 1,25 (aproximadamente)\n",
      "\n",
      "**3. Custo estimado:**\n",
      "* $ 0,0245 (24,5 tokens * 0,001)\n",
      "\n",
      "**4. Recomendações para otimização:**\n",
      "* **Remoção de duplicatas:** O texto contém trechos duplicados que podem ser removidos.\n",
      "* **Remoção de stop words:** Stop words são palavras comuns (como \"o\", \"a\", \"de\") que não contribuem muito para o significado do texto. Elas podem ser removidas.\n",
      "* **Normalização:** Converte palavras em suas formas canônicas (por exemplo, todas as palavras em letras minúsculas).\n",
      "* **Remoção de pontuação:** A pontuação não é relevante para o processamento do texto e pode ser removida.\n",
      "* **Stemming:** Reduza as palavras às suas raízes (por exemplo, \"andando\" e \"andou\" se tornam \"anda\").\n",
      "* **Lematização:** Reduz as palavras à sua forma básica (por exemplo, \"andando\" e \"andou\" se tornam \"andar\").\n"
     ]
    }
   ],
   "source": [
    "# Gerar texto de exemplo\n",
    "print(\"Gerando texto de 5000 palavras...\")\n",
    "texto_longo = gerar_texto_exemplo(5000)\n",
    "\n",
    "# Mostrar estatísticas básicas\n",
    "print(f\"\\nTamanho do texto gerado:\")\n",
    "print(f\"- Caracteres: {len(texto_longo)}\")\n",
    "print(f\"- Palavras: {len(texto_longo.split())}\")\n",
    "\n",
    "# Analisar tokens\n",
    "print(\"\\nAnalisando tokens com Gemini...\")\n",
    "resultado = analisar_tokens(texto_longo)\n",
    "print(\"\\nResultado da análise:\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Informações sobre Tokens e Custos no Gemini:\n",
      "\n",
      "1. Características dos Tokens:\n",
      "   - Um token ≈ 4 caracteres em média\n",
      "   - Palavras em português: 1.5 a 2 tokens por palavra\n",
      "   - Espaços e pontuação também contam como tokens\n",
      "\n",
      "2. Impacto nos Custos:\n",
      "   - Custo padrão: $0.001 por 1K tokens\n",
      "   - Texto de 5000 palavras: ~7500-10000 tokens\n",
      "   - Custo estimado por análise: $0.0075-$0.01\n",
      "\n",
      "3. Considerações de Desempenho:\n",
      "   - Limite do Gemini Pro: 32K tokens\n",
      "   - Maior contexto = maior tempo de processamento\n",
      "   - Textos longos podem exigir divisão em partes\n",
      "\n",
      "4. Dicas de Otimização:\n",
      "   - Remover texto redundante\n",
      "   - Dividir textos muito longos\n",
      "   - Usar resumos quando possível\n",
      "\n"
     ]
    }
   ],
   "source": [
    "info = \"\"\"\n",
    "Informações sobre Tokens e Custos no Gemini:\n",
    "\n",
    "1. Características dos Tokens:\n",
    "   - Um token ≈ 4 caracteres em média\n",
    "   - Palavras em português: 1.5 a 2 tokens por palavra\n",
    "   - Espaços e pontuação também contam como tokens\n",
    "\n",
    "2. Impacto nos Custos:\n",
    "   - Custo padrão: $0.001 por 1K tokens\n",
    "   - Texto de 5000 palavras: ~7500-10000 tokens\n",
    "   - Custo estimado por análise: $0.0075-$0.01\n",
    "\n",
    "3. Considerações de Desempenho:\n",
    "   - Limite do Gemini Pro: 32K tokens\n",
    "   - Maior contexto = maior tempo de processamento\n",
    "   - Textos longos podem exigir divisão em partes\n",
    "\n",
    "4. Dicas de Otimização:\n",
    "   - Remover texto redundante\n",
    "   - Dividir textos muito longos\n",
    "   - Usar resumos quando possível\n",
    "\"\"\"\n",
    "\n",
    "print(info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
